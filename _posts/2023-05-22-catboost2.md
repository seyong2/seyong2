---
layout: post
title: CatBoost
subtitle: Part 2 - Comparison of different encoding methods
gh-repo: seyong2
gh-badge: [star, fork, follow]
tags: [Statistics, Machine Learning, CatBoost, Encoding, One-Hot Encoding, Label Encoding, Target Encoding]
comments: true
---

In this article, my main focus will be on implementing the CatBoost algorithm discussed in my previous post on an actual dataset. If you haven't had a chance to read it yet, I recommend checking out [CatBoost Part 1 - How CatBoost deals with categorical features](https://seyong2.github.io/2023-05-21-catboost1/). The dataset I'll be working with involves the salaries of data scientists and will be used to predict their experience levels using the machine learning algorithm. If you'd like more information about the data, you can refer to [Data Science Salaries 2023](https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023). However, instead of immediately diving into the modeling aspect, I'll first explore the dataset to gain a better understanding of the relationships between its variables. To begin, let's take a look at the first five rows of the data.

| `work_year` | `experience_level` | `employment_type` | `job_title` | `salary` | `salary_currency` | `salary_in_usd`	| `employee_residence` | `remote_ratio` | `company_location` | `company_size` |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 2023 | SE | FT | Principal Data Scientist | 80000	| EUR | 85847 | ES | 100 | ES | L |
| 2023 | MI | CT | ML Engineer | 30000	| USD | 30000 | US | 100 | US | S |
| 2023 | MI | CT | ML Engineer | 25500	| USD | 25500 | US | 100 | US | S |
| 2023 | SE | FT | Data Scientist | 175000	| USD | 175000 | CA | 100 | CA | M |
| 2023 | SE | FT | Data Scientist | 120000	| USD | 120000 | CA | 100 | CA | M |

There are a total of 11 columns, with the `experience_level` column acting as the target variable for classification. The column names give us a hint about what each column represents, but we can find a detailed description of each column in the following table. Upon examining the content of the first five rows, we can also observe that the variables can be classified as either numerical or categorical. The table below indicates the column types, which are designated as either `int64` for numeric or `object` for categorical. The table also indicates that there are no missing values in the data. With a total of 3,755 rows, the "Non-Null Count" column shows that all values in the last column of the table are listed as '3755 non-null', which means that none of the features have missing values for the 3,755 rows of data.

| Column | Description |
| :---: | :---: |
| `work_year` | The year the salary was paid |
| `experience_level` | The experience level in the job during the year | 
| `employment_type` | The type of employment for the role |
| `job_title` | The role worked in during the year |
| `salary` | The total gross salary amount paid |
| `salary_currency` | The currency of the salary paid as an ISO 4217 currency code |
| `salary_in_usd` | The salary in USD |
| `employee_residence` | Employee's primary country of residence in during the work year as an ISO 3166 country code |
| `remote_ratio` | The overall amount of work done remotely | 
| `company_location` | The country of the employer's main office or contracting branch |
| `company_size` | The median number of people that worked for the company during the year |

| Column | Type | Non-Null Count |
| :---: | :---: | :---: |
| work_year | int64 | 3755 non-null |
| experience_level | object | 3755 non-null |
| employment_type | object | 3755 non-null |
| job_title | object | 3755 non-null |
| salary | int64 | 3755 non-null |
| salary_currency | object | 3755 non-null |
| salary_in_usd | int64 | 3755 non-null |
| employee_residence | object | 3755 non-null |
| remote_ratio | int64 | 3755 non-null |
| company_location | object | 3755 non-null |
| company_size | object | 3755 non-null |

- Univariate Data Analysis
  - Target Variable
    - `experience_level`  
Having obtained a brief understanding of the data, our next step involves delving deeper into the specifics by examining individual variables. The initial variable of interest is referred to as `experience_level`, which serves as the predictor variable. To comprehend a categorical variable effectively, it is common practice to utilize a bar plot that displays the frequency of observations within each category. Prior to exploring the bar plot, it is essential to grasp the significance of each category within the `experience_level` feature. This particular feature comprises four categories, namely 'EN,' 'SE,' 'MI,' and 'EX.' By analyzing the first two letters of each category, we can deduce their respective meanings: 'EN' denotes an entry-level status for a data scientist in a given year, 'SE' signifies a senior-level position, 'MI' indicates a mid/intermediate level, and 'EX' represents an executive level. Subsequently, the accompanying count plot indicates that more than half of the data scientists in the dataset (67%) held senior positions throughout the recorded periods, followed by intermediate-level individuals (21%), entry-level professionals (9%), and lastly, executives (3%).

![count_experience_level](https://github.com/seyong2/seyong2.github.io/assets/41242974/72fbb364-0664-4944-b17e-cae71879b4dc)

Moving forward, our focus will shift towards analyzing the independent features based on their respective data types. As previously observed, these features can be classified as either numeric or categorical. Initially, we will direct our attention towards the numerical variables, namely `salary_in_usd`, `remote_ratio`, and `work_year`. Although we do have another numeric feature called `salary`, for the sake of simplicity, we will exclude this column from our analysis and solely concentrate on the `salary_in_usd` variable. This decision is made to streamline our examination process, as the salary amounts have already been converted to USD dollars, eliminating the need for additional currency conversions.

  - Numeric Independent Variables
    - `salary_in_usd`
When it comes to numeric features, plotting a histogram allows us to gain insight into their distribution. Examining the histogram of `salary_in_usd`, we observe that the salary distribution skews towards the right, although the degree of skewness does not appear to be excessively pronounced. In fact, the skewness value is 0.53, indicating that the distribution possesses a greater concentration of data points in the left tail. Conversely, the kurtosis value, which indicates the presence of fat tails in the distribution, is 0.83 for `salary_in_usd`. This suggests that the variable is likely to have a smaller number of outliers compared to variables with higher kurtosis values.

Furthermore, analyzing the histogram allows us to ascertain the absence of inconsistencies within the variable. The minimum salary in USD dollars is greater than zero, indicating a logical lower limit, while the maximum salary does not exhibit an unrealistically large value.

![hist_salary](https://github.com/seyong2/seyong2.github.io/assets/41242974/bda87f63-ebbc-444a-8516-82ef27ae2842)

    - `work_year`
Moving on, let's focus on the next numeric variable, which is `work_year`. This variable represents the year in which the salary was paid. Although the values in this column are numerical, similar to `salary_in_usd`, there are only four distinct and countable values (2020, 2021, 2022, and 2023). Consequently, we can classify `work_year` as a discrete variable, in contrast to `salary_in_usd`, which is continuous. To visualize the distribution of `work_year`, we employ a count plot instead of a histogram. Upon examining the count plot, we observe that the frequencies for the years 2022 and 2023 dominate the dataset, accounting for more than 91% of the total observations. This substantial increase in frequencies suggests a rapid surge in demand for data scientist jobs starting from 2022, with the trend continuing into 2023.

![count_work_year](https://github.com/seyong2/seyong2.github.io/assets/41242974/b73b9f48-3a6c-4d24-9edd-1d79d20d933a)

    - `remote_ratio`
Lastly, let's examine the distribution of the `remote_ratio` feature. Similar to `work_year`, this feature is also discrete since it can take on only three possible values: 0 (indicating no remote work), 50 (representing partial remote work), and 100 (indicating full remote work). Once again, we can utilize a count plot to visualize the distribution of this variable, which is displayed below. From the count plot, we observe that data scientists in the dataset either work fully remotely or exclusively on-site.

It is worth noting that the distribution of `remote_ratio` may be influenced by the `work_year` variable, primarily due to the impact of the COVID-19 pandemic that emerged in 2019. It is highly likely that in the years 2020 and 2021, there was a significant increase in remote work due to the prevailing circumstances. However, as time progressed and the situation improved, it is plausible to expect a gradual decline in the proportion of remote work in subsequent years.

![count_remote_ratio](https://github.com/seyong2/seyong2.github.io/assets/41242974/bbd98094-9f8f-49f2-bb91-0ce104163e77)

  - Categorical Independent Variables
    - `employment_type`
Now let's shift our focus to the categorical features. Like the predictor variable, we will generate a count plot to examine the distribution of the categorical features. The initial variable we will analyze is `employment_type`, which consists of four categories: FT (Full-time), PT (Part-time), CT (Contractual), and FL (Freelancer). Initially, I assumed that 'contract' and 'freelance' represented the same concept. However, according to the article available at [Contractor vs Freelancer: Whatâ€™s The Difference?](https://www.talentdesk.io/blog/freelancers-vs-contractors-the-main-differences-you-should-know), contractors typically work for a single client who has control over their work location and conditions, with recurrent jobs, while freelancers work independently on multiple projects, without their hours or location being dictated. Regardless, in this dataset, the number of full-time data scientists is significantly higher compared to contractors, part-time employees, and freelancers, which together account for approximately 1% of the total observations.

![count_employment_type](https://github.com/seyong2/seyong2.github.io/assets/41242974/1ebee0d4-053a-4469-a3a8-967916789237)

    - `employee_residence`
The next categorical variable to see is `employee_residence, which tells in which country each data scientist was living during a work year. Although this is categorical, it has 78 different country names available, making it difficult to analyze this variable's distribution. Thus, I came up with the idea of mapping the countries based on the geographical location provided by [Unicef Regional Classification](https://data.unicef.org/regionalclassifications/); East Asia and Pacific, Eastern Europe and Central Asia, Western Europe, Latin America and Caribbean, Middle East and North Africa, North America, South Asia, Eastern and Southern Africa, and West and Central Africa. As expected, most data scientists resided in North America (Canada and the United States), followed by Western Europe and South Asia.

![count_employee_residence_region](https://github.com/seyong2/seyong2.github.io/assets/41242974/9746438c-bbc6-403b-97c0-210be2de5ae2)

    - `company_location`
The variable in question, which represents the location of companies where data scientists are employed, consists of country names as its values. Due to the large number of distinct values, I employed the same mapping approach used for the previous feature, `employee_residence`. After applying the mapping and examining the distribution of the feature's categories, similar to `employee_residence_region`, it became evident that a majority of the companies are situated in North America (83.4%). It is likely that this variable exhibits a correlation with `employee_residence_region`, although the strength of this relationship could be influenced by the extent to which remote work is permitted. If a company strictly requires its employees to work from the office every day and prohibits remote work, the correlation between `employee_residence_region` and `company_location_region` would be 1. Conversely, if employees have the flexibility to work from home without commuting to the office, the correlation could be significantly weaker.

![count_company_location_region](https://github.com/seyong2/seyong2.github.io/assets/41242974/ab7764e2-e62f-4ebe-ad3c-9eef8a6eadaa)

    - `company_size`
Lastly, this feature provides information about the size of the company, which is classified into three categories: S (Small), M (Medium), and L (Large). Although the exact criteria for determining the size is unknown, it is likely based on the number of employees. The count plot presented below reveals that a significant portion of the companies falls into the medium-size category. Specifically, 14% of the companies are classified as large, while a mere 4% are categorized as small.

![count_company_size](https://github.com/seyong2/seyong2.github.io/assets/41242974/5e2b4c29-076c-4d5c-914d-a2e71e906cdb)
