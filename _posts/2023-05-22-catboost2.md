---
layout: post
title: CatBoost
subtitle: Part 2 - Comparison of different encoding methods
gh-repo: seyong2
gh-badge: [star, fork, follow]
tags: [Statistics, Machine Learning, CatBoost, Encoding, One-Hot Encoding, Label Encoding, Target Encoding]
comments: true
---

This post focuses on the comparison of encoding methods discussed in the previous article. If you haven't read it yet, please take a look at [CatBoost Part 1 - How CatBoost deals with categorical features](https://seyong2.github.io/2023-05-21-catboost1/). In order to accomplish this, I will utilize the [Data Science Salaries 2023](https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023) dataset to predict the gross salary of a data scientist using a machine learning algorithm based on the available features. Before proceeding with the modeling for prediction, I will begin by exploring the dataset to gain an understanding of its structure.

To start off, I will load the dataset and examine its contents.

```
import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/ds_salaries.csv')
df.head()
```

| `work_year` | `experience_level` | `employment_type` | `job_title` | `salary` | `salary_currency` | `salary_in_usd`	| `employee_residence` | `remote_ratio` | `company_location` | `company_size` |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 2023 | SE | FT | Principal Data Scientist | 80000	| EUR | 85847 | ES | 100 | ES | L |
| 2023 | MI | CT | ML Engineer | 30000	| USD | 30000 | US | 100 | US | S |
| 2023 | MI | CT | ML Engineer | 25500	| USD | 25500 | US | 100 | US | S |
| 2023 | SE | FT | Data Scientist | 175000	| USD | 175000 | CA | 100 | CA | M |
| 2023 | SE | FT | Data Scientist | 120000	| USD | 120000 | CA | 100 | CA | M |

The presented table displays the initial five rows of the dataset. It comprises a total of 11 columns, with the `salary_in_usd` column serving as the target variable for prediction. The subsequent table provides a description of each column. Observing the variable types, it appears that the columns are categorized as either numerical or categorical. As demonstrated below, the column types are denoted as either `int64` or `object`.

| Column | Description |
| :---: | :---: |
| `work_year` | The year the salary was paid |
| `experience_level` | The experience level in the job during the year | 
| `employment_type` | The type of employment for the role |
| `job_title` | The role worked in during the year |
| `salary` | The total gross salary amount paid |
| `salary_currency` | The currency of the salary paid as an ISO 4217 currency code |
| `salary_in_usd` | The salary in USD |
| `employee_residence` | Employee's primary country of residence in during the work year as an ISO 3166 country code |
| `remote_ratio` | The overall amount of work done remotely | 
| `company_location` | The country of the employer's main office or contracting branch |
| `company_size` | The median number of people that worked for the company during the year |

```
df.dtypes
```
| Column | Type |
| :---: | :---: |
| work_year | int64 |
| experience_level | object |
| employment_type | object |
| job_title | object |
| salary | int64 | 
| salary_currency | object |
| salary_in_usd | int64 |
| employee_residence | object |
| remote_ratio | int64 |
| company_location | object |
| company_size | object |

Now that we have the brief grasp of the data, we will get into more details by examining one variable at a time. The first variable to look at is `salary_in_usd`, which is the predictor. Although we also have `salary`, we will not pay attention to it because it is more convenient to compare salaries in the same currency, not in different local currencies. Therefore, we will drop `salary`, and `salary_currency` as they are irrelevant for the analysis that we are trying to do in this post. 
