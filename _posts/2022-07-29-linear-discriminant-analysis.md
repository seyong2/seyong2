Linear discriminant analysis (LDA) tries to reduce dimensionality of data such that separability among known categories is maximized. This is done by creating a new axis given information of variables according to two criteria. The first one is that the distance between means of data projected onto the new axis should be maximized. The other one is that the variation within each category (scatter) has to be minimized. $For example, suppose that there are two categories which are known and we are interested in having a new axis that separates well the categories based on the information provided by two variables. Then, $\frac{d^2}{s_1^2+s_2^2}$ has to be as large as possible where $d$ is the distance between the two means once the data are projected onto the new axis and $s_1^2$ and $s_2^2$ are scatters of category 1 and 2, respectively.
